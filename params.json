{"name":"Object Detector with OpenCV and ROS","tagline":"ROS + OpenCV 2.4.8 integration.  Examples of object detection using  template matching, countour finding, and morphology with rospy and roscpp","body":"# Cone_detector\r\nROS + OpenCV 2.4.8 integration.  Examples of object detection using  template matching, countour finding, and morphology with rospy and roscpp\r\n\r\n\r\n\r\n### Verify Installation Requirements \r\nTo use this software you need ros-indigo, OpenCV 2.4.8, and python. \r\n\r\n* Verify OpenCV release files exist for 2.4.8:\r\n```\r\ncat /usr/share/OpenCV/OpenCVModules-release.cmake | grep 2.4.8\r\n```\r\nYou should see a lot of printouts like this:\r\n```\r\n  IMPORTED_LOCATION_RELEASE \"${_IMPORT_PREFIX}/lib/x86_64-linux-gnu/libopencv_core.so.2.4.8\"\r\n  ...\r\n```\r\n\r\n*  Check the OpenCV2 python bindings exist:\r\n```\r\n >>> import cv2\r\n\r\n```\r\n* Compile the package. Move the code directory into your `catkin_ws/src` and call `catkin_make` \r\n\r\n    *  relevant ros packages: roscpp, rospy, std_msgs, image_transport, cv_bridge, sensor_msgs, geometry_msgs\r\n\r\n\r\n### Overview of files in Obj_Detector Repository:\r\n\r\n* package.xml\r\n* CMakeLists.txt\r\n* example.bag\r\n* launch/\r\n    * cone_detector.launch\r\n    * ...\r\n* src/\r\n\r\n    * echo.py\r\n    * echo.cpp\r\n    * image_matching.py\r\n    * morphology_object_tracking.cpp\r\n    * contour.py\r\n    * blob.png\r\n    * image.png\r\n\r\n\r\n\r\n---\r\n#### example.bag\r\nA very tiny bag file that shows an orange cone.  you can test all of the code with this bag file and the .png images in the src directory.\r\n```\r\nrosbag play example.bag -a\r\n```\r\n\r\nUse `rostopic list` to see what topics are now published.\r\n\r\n#### CMakeLists\r\n\r\n`CMakeLists.txt` finds and links the OpenCV libraries and ros packages.  If you create more .cpp files you need to declare a c++ executable and add dependencies to it. \r\n\r\nAdd the bottom of CMakeLists.txt we added the following to make `echo`:\r\n```\r\nadd_executable(echo src/echo.cpp)\r\nadd_dependencies(echo ${${PROJECT_NAME}_EXPORTED_TARGETS} ${catkin_EXPORTED_TARGETS})\r\ntarget_link_libraries(echo ${OpenCV_LIBS} ${catkin_LIBRARIES}  )\r\n```\r\n\r\n#### Launch/cone_detector.launch\r\nThis package creates ros subscribers that subscribe to `~image_raw` to obtain images from a camera feed.  The launch file shows how to remap `~image_raw` to `/camera/rgb/image_rect_color`.  Modify this file to subscribe to a different image feed.\r\n\r\n\r\n---\r\n### Source Files Explanations\r\n\r\n#### echo.py and echo.cpp  (CV_BRIDGE Examples)\r\n##### Usage:\r\n```\r\nroslaunch cone_detector echo_py.launch \r\nroslaunch cone_detector echo_cpp.launch \r\n\r\n```\r\nBoth echo programs subscribe to our image topic and publish the image they recieved.  Before publishing the image message they convert the message to opencv type using cv_bridge.\r\n\r\nIn python:\r\n```python\r\n#convert sensor_msgs.msg/Image.msg  to opencv\r\nself.bridge.imgmsg_to_cv2(image_msg)\r\n\r\n#convert opencv image to sensor_msgs.msg/Image.msg:\r\nself.bridge.cv2_to_imgmsg(image_cv, \"bgr8\")\r\n```\r\n\r\nIn cpp:\r\n```\r\n// convert sensor_msgs.msg/Image.msg to opencv Mat\r\nimage = cv_bridge::toCvCopy(msg, \"bgr8\")->image;\r\n\r\n// convert Mat to sensor_mgs.msg/Image.msg\r\n msg = cv_bridge::CvImage(\r\n            std_msgs::Header(), \"bgr8\", image).toImageMsg();\r\n\r\n```\r\n\r\n##### Visualization:\r\nYou can use rqt to visualize the echo image stream. \r\n``` \r\nrqt_image_view\r\n```\r\nSelect the topic `/echo_image` or `/echo/echo_image` for cpp and python, respectively.\r\n\r\n\r\n![](https://github.com/arii/cone_detector/blob/gh-pages/echo.png?raw=true)\r\n\r\n---\r\n#### image_matching.py (Template Matching Example in Python)\r\n##### Usage:\r\nThis program uses a template image and tries to find it inside the camera feed.\r\nTo run this program, you must include the template image location:\r\n\r\n```\r\nroslaunch cone_detector cone_detector.launch image:=/home/ari/catkin_ws/src/cone/cone_detector/src/blob.png \r\n```\r\n\r\nThis program defines two classes: `ConeDetector` and `TemplateMatcher`.\r\n\r\n* ConeDetector should look very similiar to Echo.py. It has an additional ros publisher for the `cone_ibvs` topic.  This publishes a signal from [-1,1] of the cones relative location and was used for the TA's solution of IBVS parking at a cone.\r\n\r\n* TemplateMatcher uses OpenCV's `matchTemplate()` function to compare the template image to the raw image frame.   You can read about it more on their website here: http://docs.opencv.org/master/d4/dc6/tutorial_py_template_matching.html#gsc.tab=0\r\n\r\nAs you'll see many vision algorithms have different qualities.  Template matching is very susceptible to scale and rotation error.  An upright orange cone is symmetrical and will not have rotation error, however the scale will change as the robot moves toward and away the cone. We have implemented pyramid matching functionality that resizes the template image for comparison.\r\n\r\n##### Visualization:\r\nYou can use rqt to visualize the detected cone.\r\n```\r\nrqt_image_view\r\n```\r\nSelect the topic `/cone_detector/cone_detection`.\r\n\r\n![](https://github.com/arii/cone_detector/blob/gh-pages/cone_detection.png?raw=true)\r\n---\r\n#### morphology_object_tracking.cpp  (color segementation in cpp)\r\n\r\n##### Usage:\r\n```\r\nroslaunch cone_detector morphology_object_tracking.launch \r\n```\r\n\r\n\r\nThis code was adapted from here: http://opencv-srf.blogspot.com/2010/09/object-detection-using-color-seperation.html .\r\n\r\nThis code will track the cone and update its location over time.  Three opencv windows are created: control, original, and thresholded image.  In control you can change the hue, value, and saturation thresholds we are using to detect the orange cone.  The original window will display the original image with a line tracing its location over time. Lastly, threshold should display a mostly black window with the orange cone in white. If you cannot see the cone you can modify the threshold values.\r\n##### Visualization:\r\nRunning the code should automatically display three cv windows.\r\n![](https://github.com/arii/cone_detector/blob/gh-pages/morph_1.png?raw=true)\r\n![](https://github.com/arii/cone_detector/blob/gh-pages/morph_2.png?raw=true)\r\n![](https://github.com/arii/cone_detector/blob/gh-pages/morph_3.png?raw=true)\r\n---\r\n#### contour.py (Contour image detection in python)\r\n\r\n##### Usage:\r\n```\r\npython contour.py image.png\r\n```\r\n\r\ncountour.py is a simple example that does not integrate with ROS.  It simply shows the opencv functionality for finding contours. It detects the contours in the image that are with in the color min and max thresholds:\r\n```\r\nCOLOR_MIN = np.array([0, 80, 80],np.uint8)\r\nCOLOR_MAX = np.array([22, 255, 255],np.uint8)\r\n```\r\n\r\nNote that the image was first converted into HSV colorspace. The color orange has a hue of around 0 - 22, which is why the thresholds was set this way.\r\n\r\nThis program plots a box around the largest contour within our color specified thresholds.\r\n\r\n\r\n##### Visualization:\r\nRunning the code should automatically display one cv window. \r\n![](https://github.com/arii/cone_detector/blob/gh-pages/contour.png?raw=true)\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}